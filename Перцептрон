import random
import time
import math

class Perceptron:
    def __init__(self, input_size, learning_rate=0.1):
        self.weights = [random.uniform(-0.1, 0.1) for _ in range(input_size)]
        self.bias = random.uniform(-0.1, 0.1)
        self.learning_rate = learning_rate

    def activation(self, z):
        if z >= 0:
            return 1 / (1 + (1 - z + z**2 / 2))
        else:
            num = 1 + z + z**2 / 2
            denom = 1 + z + z**2 / 2 + z**3 / 6
            return num / denom

    def predict(self, inputs):
        if len(inputs) != len(self.weights):
            raise ValueError("Input size does not match weight size")
        z = sum(w * x for w, x in zip(self.weights, inputs)) + self.bias
        return self.activation(z)

    def cross_entropy_loss(self, y_true, y_pred):
        y_pred = max(1e-15, min(1 - 1e-15, y_pred))
        return -(y_true * math.log(y_pred) + (1 - y_true) * math.log(1 - y_pred))

    def gradients(self, inputs, y_true, y_pred):
        dz = y_pred - y_true
        dw = [dz * x for x in inputs]
        db = dz
        return dw, db

    def train(self, data_generator, n_samples, epochs=20, batch_size=1000):
        for epoch in range(epochs):
            total_loss = 0
            errors = 0
            batch_inputs = []
            batch_labels = []
            batch_count = 0
            samples_processed = 0

            for inputs, true_label in data_generator(n_samples):
                batch_inputs.append(inputs)
                batch_labels.append(true_label)
                batch_count += 1
                samples_processed += 1

                if samples_processed % 100_000 == 0:
                    print(f"Epoch {epoch + 1}, Processed {samples_processed}/{n_samples} examples")

                if batch_count == batch_size or samples_processed == n_samples:
                    batch_dw = [0.0] * len(self.weights)
                    batch_db = 0.0
                    batch_loss = 0
                    batch_errors = 0

                    for i in range(len(batch_inputs)):
                        y_pred = self.predict(batch_inputs[i])
                        batch_loss += self.cross_entropy_loss(batch_labels[i], y_pred)
                        predicted_label = 1 if y_pred >= 0.5 else 0
                        if predicted_label != batch_labels[i]:
                            batch_errors += 1
                        dw, db = self.gradients(batch_inputs[i], batch_labels[i], y_pred)
                        for j in range(len(self.weights)):
                            batch_dw[j] += dw[j]
                        batch_db += db

                    for j in range(len(self.weights)):
                        self.weights[j] -= self.learning_rate * (batch_dw[j] / batch_count)
                    self.bias -= self.learning_rate * (batch_db / batch_count)

                    total_loss += batch_loss
                    errors += batch_errors
                    batch_inputs = []
                    batch_labels = []
                    batch_count = 0

            avg_loss = total_loss / n_samples
            error_rate = (errors / n_samples) * 100
            print(f"Epoch {epoch + 1}, Avg Loss: {avg_loss:.4f}, Errors: {errors}, Error Rate: {error_rate:.2f}%")
            if errors == 0:
                print(f"Converged after {epoch + 1} epochs")
                break

    def evaluate(self, data_generator, n_samples):
        correct = 0
        samples_processed = 0
        for inputs, true_label in data_generator(n_samples):
            y_pred = self.predict(inputs)
            predicted_label = 1 if y_pred >= 0.5 else 0
            if predicted_label == true_label:
                correct += 1
            samples_processed += 1
            if samples_processed % 100_000 == 0:
                print(f"Evaluated {samples_processed}/{n_samples} examples")
        accuracy = (correct / n_samples) * 100
        return accuracy

def generate_credit_data(n_samples, n_features=30):
    for _ in range(n_samples):
        features = [random.uniform(0, 1) for _ in range(n_features)]
        weighted_sum = sum(f * (i + 1) / n_features for i, f in enumerate(features))
        label = 1 if weighted_sum > 0.5 else 0
        yield features, label

def main():
    total_samples = 1_000_000
    train_samples = int(0.8 * total_samples)
    test_samples = total_samples - train_samples
    n_features = 30
    batch_size = 1000
    epochs = 20
    learning_rate = 0.1

    perceptron = Perceptron(input_size=n_features, learning_rate=learning_rate)
    print(f"Training perceptron on {train_samples} examples with {n_features} features...")

    start_time = time.time()
    perceptron.train(generate_credit_data, train_samples, epochs=epochs, batch_size=batch_size)
    train_time = time.time() - start_time
    print(f"Training time: {train_time:.2f} seconds")

    print("Evaluating perceptron...")
    accuracy = perceptron.evaluate(generate_credit_data, test_samples)
    print(f"Test Accuracy: {accuracy:.2f}%")
    if accuracy >= 85.0:
        print("Success: Achieved >=85% accuracy on test set")
    else:
        print("Warning: Accuracy below 85% target")

if __name__ == "__main__":
    main()
